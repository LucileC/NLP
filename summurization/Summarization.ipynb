{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 14261 pieces of data\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "path = \"data/msmarco_2wellformed/dev_v2.0_well_formed.json\"\n",
    "\n",
    "def loadDataset(path,limit=100000000000):\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset = list()\n",
    "    i = 0\n",
    "    for line in open(path, 'r'):\n",
    "        all_data = json.loads(line)\n",
    "        for data in all_data:\n",
    "            if i <limit:\n",
    "                dataset.append(data)\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "    print(\"Loaded %d pieces of data\"%len(dataset))\n",
    "    return dataset\n",
    "\n",
    "dataset = loadDataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is radioactive waste\n",
      "bacteria that causes tonsillitis\n",
      "what type of solution hypochlorous acid\n",
      "what is a surety bond for bail\n",
      "what is the language of c language?\n",
      "cognitive impairment definition\n",
      "is mitochondria in plant or animal cells\n",
      "cooking time for pork loin roast in oven\n",
      "how snake breathe\n",
      "what cause water fluid build up on  joints\n",
      "when did the abolitionist movement start\n",
      "how tall is ed harris\n",
      "how long is someone contagious for strep\n",
      "cra business phone number\n",
      "what causes hands to peel skin\n",
      "what county is box springs, georgia\n",
      "who regulates cell phone companies in texas\n",
      "what party was fdr\n",
      "which printer support both mac and hp\n",
      "evading arrest definition\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "#     print('')\n",
    "    x = random.choice(dataset)\n",
    "    print(x['query'])\n",
    "#     print(x['wellFormedAnswers'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'can', \"n't\", 'open', 'the', 'door', 'because', 'the', '30-year', 'old', '/', 'blond-hair', 'guy', 'does', \"n't\", 'want', 'to', 'let', 'me', 'in', '.', 'he', \"'s\", 'mean', ',', 'is', \"n't\", 'he', '?', 'i', 'can', \"n't\", 'go', 'in', '!', 'there', \"'s\", 'no', 'other', 'way', '!']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# def processFinalPeriod(sentence1):\n",
    "# \tif (sentence1[len(sentence1)-1] == \".\"):\n",
    "# \t\tsentence1 = sentence1[:len(sentence1)-2] + \" .\"\n",
    "\n",
    "def insertCharIfSeq(sentence1,c,seq):\n",
    "    i = 0\n",
    "    indexes = [m.start() for m in re.finditer(seq, sentence1)]\n",
    "    for index in indexes:\n",
    "        sentence1 = sentence1[:index+i] + c + sentence1[index+i:]\n",
    "        i += 1\n",
    "    return sentence1\n",
    "\n",
    "def processContractions(sentence1):\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'s\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'m\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'ll\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'ve\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'re\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'d\")\n",
    "    return sentence1\n",
    "\n",
    "\n",
    "def processNegatives(sentence1):\n",
    "    i = 0\n",
    "    indexes = [m.start() for m in re.finditer(\"can't\", sentence1)]\n",
    "    for index in indexes:\n",
    "        sentence1 = sentence1[:index+i+3] + sentence1[index+i+2:]\n",
    "        i += 1\n",
    "    return insertCharIfSeq(sentence1,\" \",\"n't\")\n",
    "\n",
    "## WHAT TO DO WITH HYPHENS ??\n",
    "\n",
    "def tokenizeSentence(sentence1):\n",
    "#     processFinalPeriod(sentence1)\n",
    "    sentence1 = processContractions(sentence1)\n",
    "    sentence1 = processNegatives(sentence1)\n",
    "    s = sentence1.lower()\n",
    "    s = re.sub('''([.,!\"?$;:/#`()])''', r' \\1 ', s)\n",
    "    s = re.sub('\\s{2,}', ' ', s)\n",
    "    s = s.split()\n",
    "#     s = processHyphenIfUnknownWords(s,glove)\n",
    "#     s.append('</s>')\n",
    "#     s = ['<s>'] + s\n",
    "    return s\n",
    "\n",
    "def testTokenizeSentence():\n",
    "    sentence1 = \"I can't open the door because the 30-year old/blond-hair guy doesn't want to let me in. He's mean, isn't he? I can't go in! There's no other way!\"\n",
    "    words = tokenizeSentence(sentence1)\n",
    "    print(words)\n",
    "    \n",
    "testTokenizeSentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 3: \"UNK\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence:\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n",
      "Number of different words: 173707\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "vocab = Vocab()\n",
    "\n",
    "def tokenizeDataset(dataset):\n",
    "    tokenized_dataset = list()\n",
    "    len_dataset = len(dataset)\n",
    "    print_every = math.floor(len_dataset / 10)\n",
    "    print('Tokenizing dataset...')\n",
    "    for i, data in enumerate(dataset):\n",
    "        tokenized_data = dict()\n",
    "        tokenized_data['answers'] = list()\n",
    "        tokenized_data['wellFormedAnswers'] = list()\n",
    "        tokenized_data['passages'] = list()\n",
    "        for answer in data['answers']:\n",
    "            t = tokenizeSentence(answer)\n",
    "            tokenized_data['answers'].append(t)\n",
    "            vocab.addSentence(t)\n",
    "        for wf_answer in data['wellFormedAnswers']:\n",
    "            t = tokenizeSentence(wf_answer)\n",
    "            tokenized_data['wellFormedAnswers'].append(t)\n",
    "            vocab.addSentence(t)\n",
    "        for passage in data['passages']:\n",
    "            t = tokenizeSentence(passage['passage_text'])\n",
    "            tokenized_data['passages'].append(t)\n",
    "            vocab.addSentence(t)\n",
    "        if i>0 and i%print_every == 0:\n",
    "            print('... %d%%'%(i/print_every*10),end=\"\\r\")\n",
    "        tokenized_dataset.append(tokenized_data)\n",
    "            \n",
    "    print('Number of different words: %d'%vocab.n_words)\n",
    "    \n",
    "    return tokenized_dataset\n",
    "\n",
    "tokenized_data = tokenizeDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "VOC_SIZE = vocab.n_words#50000 #for both source and target\n",
    "OUTPUT_SIZE = VOC_SIZE #10 # ?? \n",
    "BASELINE_VOC_SIZE = vocab.n_words\n",
    "MAX_LENGTH = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([569, 1])\n",
      "torch.Size([12, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def indexesFromSentence(sentence): # sentence is a list of tokens\n",
    "    return [vocab.word2index[word] for word in sentence]\n",
    "        \n",
    "def variableFromSentence(sentence):\n",
    "    indexes = indexesFromSentence(sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return Variable(torch.LongTensor(indexes).view(-1,1))\n",
    "                    \n",
    "def variablesFromPair(pair):\n",
    "    input_var = variableFromSentence(pair[0])\n",
    "    target_var = variableFromSentence(pair[1])\n",
    "    return input_var, target_var\n",
    "        \n",
    "example = random.choice(tokenized_data)\n",
    "# print(example['passages'])\n",
    "input_var = [item for sublist in example['passages'] for item in sublist]\n",
    "input_var = variableFromSentence(input_var)\n",
    "print(input_var.size())\n",
    "target_var = example['wellFormedAnswers'][0]\n",
    "target_var = variableFromSentence(target_var)\n",
    "print(target_var.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([569, 1])\n",
      "torch.Size([569, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class EncoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,embedding_size=EMBEDDING_SIZE,hidden_size=HIDDEN_SIZE,voc_size=VOC_SIZE):\n",
    "        super(EncoderLSTM,self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.voc_size = voc_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(voc_size, embedding_size)\n",
    "        self.bilstm = nn.LSTM(embedding_size, hidden_size, num_layers =1, bidirectional=True)\n",
    "                \n",
    "    def initHidden(self):\n",
    "        return (Variable(torch.zeros(2, 1, self.hidden_size)), # 2 because bidirectional\n",
    "                Variable(torch.zeros(2, 1, self.hidden_size)))\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.bilstm(embedded, hidden)\n",
    "        return hidden\n",
    "        \n",
    "encoder = EncoderLSTM()\n",
    "input_length = len(input_var)\n",
    "encoder_hidden = encoder.initHidden()        \n",
    "h = Variable(torch.zeros(input_length, encoder.hidden_size*2))        \n",
    "for ei in range(input_length):\n",
    "    encoder_hidden = encoder(input_var[ei],encoder_hidden)\n",
    "    h[ei] = torch.cat((encoder_hidden[0][0],encoder_hidden[1][0]),1)\n",
    "print(input_var.size())\n",
    "print(h.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-06 *\n",
      " -5.7138\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class AttnDecoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,embedding_size=EMBEDDING_SIZE,hidden_size=HIDDEN_SIZE,output_size=OUTPUT_SIZE,\n",
    "                 voc_size=VOC_SIZE,max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderLSTM,self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.voc_size = voc_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(voc_size, embedding_size)\n",
    "        self.decoder_bilstm = nn.LSTM(self.embedding_size,self.hidden_size, num_layers=1, bidirectional = True)\n",
    "        self.attn_Ws = nn.Linear(hidden_size *2, hidden_size) #?\n",
    "        self.attn_Wh = nn.Linear(hidden_size *2, hidden_size) #?\n",
    "        self.attn_v = nn.Linear(hidden_size, 1)\n",
    "        self.lin_V1 = nn.Linear(hidden_size*4, hidden_size)\n",
    "        self.lin_V2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return (Variable(torch.zeros(2, 1, self.hidden_size)), # 2 because bidirectional\n",
    "                Variable(torch.zeros(2, 1, self.hidden_size)))\n",
    "        \n",
    "    def forward(self,input,hidden,h):\n",
    "        emb = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.decoder_bilstm(emb,hidden)\n",
    "        s_t = torch.cat((hidden[0][0],hidden[1][0]),1)\n",
    "        \n",
    "        # attention distribution\n",
    "        Wh = self.attn_Wh(h) # dim: number of words in input , 256\n",
    "        Ws_t = self.attn_Ws(s_t) # dim: 1 , 256\n",
    "        Wh_Ws_t_d = torch.add(Wh,Ws_t) # dim: number of words in input , 256 \n",
    "        Wh_Ws_t_d = F.tanh(Wh_Ws_t_d) # dim: number of words in input , 256 \n",
    "        e_t = self.attn_v(Wh_Ws_t_d) # dim: number of words in input , 1 \n",
    "        e_t = torch.t(e_t) # dim: 1, number of words in input\n",
    "        a_t = F.softmax(e_t, dim=1) # dim: 1, number of words in input\n",
    "        hstar_t = torch.bmm(a_t.unsqueeze(0),h.unsqueeze(0)) # dim: 1, 1 , 512\n",
    "        # vocabulary distribution\n",
    "        v1 = torch.cat((s_t.unsqueeze(0),hstar_t),dim=2) # dim: 1, 1, 1024\n",
    "        v1 = self.lin_V1(v1) # dim: 1, 1, 256\n",
    "        v2 = self.lin_V2(v1) # dim: 1, 1, vocabulary size\n",
    "        Pvocab = F.softmax(v2,dim=2) # dim: 1, 1, vocabulary size\n",
    "        \n",
    "        return Pvocab[0], hidden    \n",
    "      \n",
    "decoder = AttnDecoderLSTM()\n",
    "target_length = len(target_var)\n",
    "hidden = decoder.initHidden()         \n",
    "input = Variable(torch.LongTensor([[SOS_token]]))      \n",
    "loss = 0\n",
    "criterion = nn.NLLLoss()\n",
    "for di in range(target_length):\n",
    "    output, hidden = decoder(input, hidden, h)\n",
    "#     outputs[di] = output\n",
    "    input = target_var[di]\n",
    "\n",
    "    loss += criterion(output,target_var[di])\n",
    "print (loss/target_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 512])\n",
      "Variable containing:\n",
      "1.00000e-06 *\n",
      " -6.1814\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class AttnDecoderLSTM2(nn.Module):\n",
    "    \n",
    "    def __init__(self,embedding_size=EMBEDDING_SIZE,hidden_size=HIDDEN_SIZE,output_size=OUTPUT_SIZE,\n",
    "                 voc_size=VOC_SIZE,max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderLSTM2,self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.voc_size = voc_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(voc_size, embedding_size)\n",
    "        self.decoder_bilstm = nn.LSTM(self.embedding_size,self.hidden_size, num_layers=1, bidirectional = True)\n",
    "        self.attn_Ws = nn.Linear(hidden_size *2, hidden_size) #?\n",
    "        self.attn_Wh = nn.Linear(hidden_size *2, hidden_size) #?\n",
    "        self.attn_v = nn.Linear(hidden_size, 1)\n",
    "        self.lin_V1 = nn.Linear(hidden_size*4, hidden_size)\n",
    "        self.lin_V2 = nn.Linear(hidden_size, output_size)\n",
    "        self.test = nn.Linear(hidden_size*2,output_size)\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return (Variable(torch.zeros(2, 1, self.hidden_size)), # 2 because bidirectional\n",
    "                Variable(torch.zeros(2, 1, self.hidden_size)))\n",
    "        \n",
    "    def forward_rec(self,input,hidden):\n",
    "        emb = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.decoder_bilstm(emb,hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "\n",
    "    def forward(self, target_var, h):\n",
    "        input_length = h.size()[0]\n",
    "        target_length = len(target_var)\n",
    "        hidden = self.initHidden()        \n",
    "        outputs = Variable(torch.zeros(target_length, self.hidden_size*2))  \n",
    "        s = Variable(torch.zeros(target_length,self.hidden_size*2))\n",
    "        input = Variable(torch.LongTensor([[SOS_token]]))    \n",
    "        \n",
    "        for di in range(target_length):\n",
    "            output, hidden = self.forward_rec(input, hidden)\n",
    "            outputs[di] = output[0]\n",
    "            s[di] = torch.cat((hidden[0][0],hidden[1][0]),1)\n",
    "            input = target_var[di]\n",
    "        \n",
    "        # attention distribution\n",
    "        Wh = self.attn_Wh(h) # dim: # of words in input , 256\n",
    "        Ws = self.attn_Ws(s) # dim: # of words in target , 256\n",
    "        Wh_Ws_d = Variable(torch.zeros(target_length,input_length,256)) # dim: # of words in target, # of words in input , 256 \n",
    "        for i in range(target_length):\n",
    "            Wh_Ws_d[i] = torch.add(Wh,Ws[0])\n",
    "        Wh_Ws_d = F.tanh(Wh_Ws_d) # dim: # of words in target, # of words in input , 256 \n",
    "        e = self.attn_v(Wh_Ws_d) # dim: # of words in target, # of words in input , 1 \n",
    "        e = e.permute(0,2,1) # dim: # of words in target, 1, # of words in input \n",
    "        a = F.softmax(e, dim=2) # dim: # of words in target, 1, # of words in input \n",
    "        h_extended = torch.add(Variable(torch.zeros(target_length,input_length,self.hidden_size*2)),h)\n",
    "        hstar = torch.bmm(a,h_extended) # dim: #of target words, 1, 512\n",
    "        # vocabulary distribution\n",
    "        v1 = torch.cat((s.unsqueeze(1),hstar),dim=2) # dim: #of target words, 1, 1024\n",
    "        v1 = self.lin_V1(v1) # dim: #of target words, 1, 256\n",
    "        v2 = self.lin_V2(v1) # dim: #of target words, 1, vocabulary size\n",
    "        Pvocab = F.softmax(v2,dim=2) # dim: #of target words, 1, vocabulary size\n",
    "        x = self.test(s).unsqueeze(1)\n",
    "        print(s.size())\n",
    "        Pvocab = F.softmax(x,2)\n",
    "        \n",
    "        return Pvocab, outputs    \n",
    "      \n",
    "decoder2 = AttnDecoderLSTM2()\n",
    "loss = 0\n",
    "Pvocab, outputs = decoder2(target_var,h)\n",
    "criterion = nn.NLLLoss()\n",
    "for i in range(len(outputs)):\n",
    "    loss += criterion(Pvocab[i],target_var[i])\n",
    "print (loss/len(target_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-06 *\n",
      " -5.7498\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class AttnDecoderLSTM3(nn.Module):\n",
    "    \n",
    "    def __init__(self,embedding_size=EMBEDDING_SIZE,hidden_size=HIDDEN_SIZE,output_size=OUTPUT_SIZE,\n",
    "                 voc_size=VOC_SIZE,max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderLSTM3,self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.voc_size = voc_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(voc_size, embedding_size)\n",
    "        self.decoder_bilstm = nn.LSTM(self.embedding_size,self.hidden_size, num_layers=1, bidirectional = True)\n",
    "        self.linear = nn.Linear(hidden_size*2, output_size)\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return (Variable(torch.zeros(2, 1, self.hidden_size)), # 2 because bidirectional\n",
    "                Variable(torch.zeros(2, 1, self.hidden_size)))\n",
    "        \n",
    "    def forward(self,input,hidden,h):\n",
    "        emb = self.embedding(input).view(1,1,-1)\n",
    "        x, hidden = self.decoder_bilstm(emb,hidden)\n",
    "        x = self.linear(x)\n",
    "        x = F.softmax(x,dim=2)\n",
    "        \n",
    "        return x[0], hidden    \n",
    "      \n",
    "decoder3 = AttnDecoderLSTM3()\n",
    "target_length = len(target_var)\n",
    "hidden = decoder.initHidden()         \n",
    "input = Variable(torch.LongTensor([[SOS_token]]))      \n",
    "loss = 0\n",
    "criterion = nn.NLLLoss()\n",
    "for di in range(target_length):\n",
    "    output, hidden = decoder(input, hidden, h)\n",
    "#     outputs[di] = output\n",
    "    input = target_var[di]\n",
    "\n",
    "    loss += criterion(output,target_var[di])\n",
    "print (loss/target_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-05 *\n",
      " -1.7712\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,embedding_size=EMBEDDING_SIZE,hidden_size=HIDDEN_SIZE,output_size=OUTPUT_SIZE,\n",
    "                 voc_size=VOC_SIZE,max_length=MAX_LENGTH):\n",
    "        super(DecoderLSTM,self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.voc_size = voc_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(voc_size, embedding_size)\n",
    "        self.decoder_bilstm = nn.LSTM(self.embedding_size,self.hidden_size, num_layers=1, bidirectional = True)\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return (Variable(torch.zeros(2, 1, self.hidden_size)), # 2 because bidirectional\n",
    "                Variable(torch.zeros(2, 1, self.hidden_size)))\n",
    "        \n",
    "    def forward(self,input,hidden):\n",
    "        emb = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.decoder_bilstm(emb,hidden)\n",
    "        return output, hidden \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, embedding_size=EMBEDDING_SIZE,hidden_size=HIDDEN_SIZE,output_size=OUTPUT_SIZE,\n",
    "                 voc_size=VOC_SIZE,max_length=MAX_LENGTH):\n",
    "        super(Attention,self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.voc_size = voc_size\n",
    "        \n",
    "        self.attn_Ws = nn.Linear(hidden_size *2, hidden_size) #?\n",
    "        self.attn_Wh = nn.Linear(hidden_size *2, hidden_size) #?\n",
    "        self.attn_v = nn.Linear(hidden_size, 1)\n",
    "        self.lin_V1 = nn.Linear(hidden_size*4, hidden_size)\n",
    "        self.lin_V2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self,h,s):\n",
    "        # attention distribution\n",
    "        Wh = self.attn_Wh(h) # dim: # of words in input , 256\n",
    "        Ws = self.attn_Ws(s) # dim: # of words in target , 256\n",
    "        Wh_Ws_d = Variable(torch.zeros(target_length,input_length,256)) # dim: # of words in target, # of words in input , 256 \n",
    "        for i in range(target_length):\n",
    "            Wh_Ws_d[i] = torch.add(Wh,Ws[0])\n",
    "        Wh_Ws_d = F.tanh(Wh_Ws_d) # dim: # of words in target, # of words in input , 256 \n",
    "        e = self.attn_v(Wh_Ws_d) # dim: # of words in target, # of words in input , 1 \n",
    "        e = e.permute(0,2,1) # dim: # of words in target, 1, # of words in input \n",
    "        a = F.softmax(e, dim=2) # dim: # of words in target, 1, # of words in input \n",
    "        h_extended = torch.add(Variable(torch.zeros(target_length,input_length,self.hidden_size*2)),h)\n",
    "        hstar = torch.bmm(a,h_extended) # dim: #of target words, 1, 512\n",
    "        # vocabulary distribution\n",
    "        v1 = torch.cat((s.unsqueeze(1),hstar),dim=2) # dim: #of target words, 1, 1024\n",
    "        v1 = self.lin_V1(v1) # dim: #of target words, 1, 256\n",
    "        v2 = self.lin_V2(v1) # dim: #of target words, 1, vocabulary size\n",
    "        Pvocab = F.softmax(v2,dim=2) # dim: #of target words, 1, vocabulary size\n",
    "        return Pvocab\n",
    "      \n",
    "decoder4 = DecoderLSTM()\n",
    "        \n",
    "target_length = len(target_var)\n",
    "outputs = Variable(torch.zeros(target_length, decoder4.hidden_size*2))  \n",
    "s = Variable(torch.zeros(target_length,decoder4.hidden_size*2))\n",
    "input = Variable(torch.LongTensor([[SOS_token]]))   \n",
    "hidden = decoder4.initHidden()\n",
    "\n",
    "for di in range(target_length):\n",
    "    output, hidden = decoder4(input, hidden)\n",
    "    outputs[di] = output[0]\n",
    "    s[di] = torch.cat((hidden[0][0],hidden[1][0]),1)\n",
    "    input = target_var[di]\n",
    "    \n",
    "attention = Attention()\n",
    "pvocab = attention(h,s)\n",
    "for i in range(len(outputs)):\n",
    "    loss += criterion(Pvocab[i],target_var[i])\n",
    "print (loss/len(target_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s/60)\n",
    "    s -= m*60\n",
    "    return '%dm %ds' %(m,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting encoding\n",
      "Starting decoding, target_length = 12\n",
      "Starting backprop\n",
      "Done with backprop, took 0m 44s\n",
      "-5.645414906515119e-06\n"
     ]
    }
   ],
   "source": [
    "def trainingStep(input_var, target_var, encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH, debug=False):\n",
    "    \n",
    "    if debug:\n",
    "        print('Starting encoding')\n",
    "        \n",
    "    input_length = len(input_var)\n",
    "    encoder_hidden = encoder.initHidden()        \n",
    "    h = Variable(torch.zeros(input_length, encoder.hidden_size*2))        \n",
    "    for ei in range(input_length):\n",
    "        encoder_hidden = encoder(input_var[ei],encoder_hidden)\n",
    "        h[ei] = torch.cat((encoder_hidden[0][0],encoder_hidden[1][0]),1)\n",
    "\n",
    "    target_length = len(target_var)\n",
    "    decoder_hidden = decoder.initHidden()        \n",
    "#     s = Variable(torch.zeros(target_length, decoder.hidden_size))   \n",
    "#     decoder_outputs = Variable(torch.zeros(target_length, decoder.output_size))      \n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))      \n",
    "        \n",
    "    if debug:\n",
    "        print('Starting decoding, target_length = %d'%target_length)\n",
    "    \n",
    "    loss = 0\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, h)\n",
    "        loss += criterion(decoder_output,target_var[di])\n",
    "        \n",
    "    if debug:\n",
    "        start = time.time()\n",
    "        print('Starting backprop')\n",
    "    loss.backward()    \n",
    "    if debug:\n",
    "        print('Done with backprop, took %s'%timeSince(start))\n",
    "        \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "\n",
    "encoder_opt = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder_opt = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder = AttnDecoderLSTM()\n",
    "loss = trainingStep(input_var,target_var,encoder,decoder,encoder_opt,decoder_opt,nn.NLLLoss(),debug=True)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting encoding\n",
      "Starting decoding, target_length = 12\n",
      "torch.Size([12, 512])\n",
      "Starting backprop\n",
      "Done with backprop, took 0m 1s\n",
      "-5.514753866009414e-06\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def trainingStep2(input_var, target_var, encoder, decoder22, encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH, debug=False):\n",
    "    \n",
    "    if debug:\n",
    "        print('Starting encoding')\n",
    "        \n",
    "    input_length = len(input_var)\n",
    "    encoder_hidden = encoder.initHidden()        \n",
    "    h = Variable(torch.zeros(input_length, encoder.hidden_size*2))        \n",
    "    for ei in range(input_length):\n",
    "        encoder_hidden = encoder(input_var[ei],encoder_hidden)\n",
    "        h[ei] = torch.cat((encoder_hidden[0][0],encoder_hidden[1][0]),1)\n",
    "\n",
    "    target_length = len(target_var)    \n",
    "    if debug:\n",
    "        print('Starting decoding, target_length = %d'%target_length)\n",
    "    \n",
    "    Pvocab, outputs = decoder22(target_var,h)\n",
    "    loss = 0\n",
    "    for i in range(target_length):\n",
    "        loss += criterion(Pvocab[i],target_var[i])        \n",
    "        \n",
    "    if debug:\n",
    "        start = time.time()\n",
    "        print('Starting backprop')\n",
    "    loss.backward()    \n",
    "    if debug:\n",
    "        print('Done with backprop, took %s'%timeSince(start))\n",
    "        \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "\n",
    "encoder_opt = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder_opt = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder22 = AttnDecoderLSTM2()\n",
    "loss = trainingStep2(input_var,target_var,encoder,decoder22,encoder_opt,decoder_opt,nn.NLLLoss(),debug=True)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting encoding\n",
      "Starting decoding, target_length = 27\n",
      "Starting backprop\n",
      "Done with backprop, took 0m 46s\n",
      "-5.813038485400655e-06\n"
     ]
    }
   ],
   "source": [
    "def trainingStep4(input_var, target_var, encoder, decoder4, attention, encoder_optimizer, decoder_optimizer, \n",
    "                  attention_optimizer, criterion, max_length=MAX_LENGTH, debug=False):\n",
    "    \n",
    "    if debug:\n",
    "        print('Starting encoding')\n",
    "        \n",
    "    input_length = len(input_var)\n",
    "    encoder_hidden = encoder.initHidden()        \n",
    "    h = Variable(torch.zeros(input_length, encoder.hidden_size*2))        \n",
    "    for ei in range(input_length):\n",
    "        encoder_hidden = encoder(input_var[ei],encoder_hidden)\n",
    "        h[ei] = torch.cat((encoder_hidden[0][0],encoder_hidden[1][0]),1)\n",
    "\n",
    "    target_length = len(target_var)    \n",
    "    if debug:\n",
    "        print('Starting decoding, target_length = %d'%target_length)\n",
    "    \n",
    "    \n",
    "    outputs = Variable(torch.zeros(target_length, decoder4.hidden_size*2))  \n",
    "    s = Variable(torch.zeros(target_length,decoder4.hidden_size*2))\n",
    "    input = Variable(torch.LongTensor([[SOS_token]]))  \n",
    "    hidden = decoder4.initHidden()  \n",
    "\n",
    "    for di in range(target_length):\n",
    "        output, hidden = decoder4(input, hidden)\n",
    "        outputs[di] = output[0]\n",
    "        s[di] = torch.cat((hidden[0][0],hidden[1][0]),1)\n",
    "        input = target_var[di]\n",
    "    \n",
    "    attention = Attention()\n",
    "    pvocab = attention(h,s)\n",
    "    loss = 0\n",
    "    for i in range(len(outputs)):\n",
    "        loss += criterion(pvocab[i],target_var[i])\n",
    "\n",
    "    if debug:\n",
    "        start = time.time()\n",
    "        print('Starting backprop')\n",
    "    loss.backward()    \n",
    "    if debug:\n",
    "        print('Done with backprop, took %s'%timeSince(start))\n",
    "        \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "\n",
    "encoder_opt = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder_opt = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "attn_opt = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "loss = trainingStep4(input_var,target_var,encoder,decoder4,attention,encoder_opt,decoder_opt,attn_opt,nn.NLLLoss(),debug=True)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
