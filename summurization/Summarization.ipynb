{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 14261 pieces of data\n",
      "\n",
      "what chemical in capacitor leak\n",
      "Electrolyte chemical is in capacitor leak.\n",
      "\n",
      "what county is saucier\n",
      "Saucier is in Harrison County.\n",
      "\n",
      "what is food?\n",
      "Food is any substance consumed to provide nutritional support for an organism.  \n",
      "\n",
      "what phylicia rashad says about the cosby trial\n",
      "Phylicia Rashad is speaking out about the Bill Cosby sexual assault allegations, defending her longtime friend. “I love him,” she told Roger Friedman's Showbiz 411 earlier this week at Paramount's lunch for the movie Selma.\n",
      "\n",
      "what is an example of a certified public record\n",
      "The example of a certified public record is Marriage Records.\n",
      "\n",
      "are breitling watches made in japan\n",
      "Yes, Breitling watches are not made in Japan.\n",
      "\n",
      "population socorro new mexico\n",
      "The population of Socorro, New Mexico is 8,906.\n",
      "\n",
      "what hazchem indicates\n",
      "The top-left section of the plate gives the Emergency Action Code telling the fire brigade what actions to take if there's an accident is indicated in Hazchem.\n",
      "\n",
      "what does an allergy do to you\n",
      "An allergy can cause headaches. If it is something you breathe in from the air, the reaction will affect your eyes, nose and lungs. If it is something you eat, it may affect your mouth, stomach and intestines.\n",
      "\n",
      "who is jaleel white dead?\n",
      "Jaleel White Dead is an American actor, voice actor, producer and screenwriter.\n",
      "\n",
      "price of new honda civic\n",
      "The price of New Honda Civic is $15,650 to $35,705.\n",
      "\n",
      "average cost of commercial janitorial services\n",
      "The average cost of commercial janitorial services is $. 05 to $. 10 per square foot. \n",
      "\n",
      "why do dry eyes tear\n",
      "Dry eyes can result from an improper balance of tear production and drainage.\n",
      "\n",
      "where is the plantar aponeurosis\n",
      "The plantar aponeurosis is located on the bottom of the foot.\n",
      "\n",
      "population cottage grove, oregon\n",
      "The population of Cottage Grove, Oregon is 9,686.  \n",
      "\n",
      "how long does it take for tendon to heal\n",
      "It takes close to a year long for tendon to heal.\n",
      "\n",
      "how many aircraft in a squadron\n",
      "There are 12 to 24 aircraft in a squadron.\n",
      "\n",
      "what is slippery elm tea\n",
      "The slippery elm tea is a large, deciduous tree that is native to North American from Texas to Manitoba, and from Florida to Quebec.\n",
      "\n",
      "tree of heroes des moines memorial drive\n",
      "There are over 1,400 tree on the heroes Des Moines Memorial Drive.\n",
      "\n",
      "how should an newborn sleep\n",
      "A newborn should sleep for 16 to 20 hours a day in 3 to 4 hour stretches.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "path = \"data/msmarco_2wellformed/dev_v2.0_well_formed.json\"\n",
    "\n",
    "def loadDataset(path,limit=100000000000):\n",
    "    print(\"Loading dataset...\")\n",
    "    dataset = list()\n",
    "    i = 0\n",
    "    for line in open(path, 'r'):\n",
    "        all_data = json.loads(line)\n",
    "        for data in all_data:\n",
    "            if i <limit:\n",
    "                dataset.append(data)\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "    print(\"Loaded %d pieces of data\"%len(dataset))\n",
    "    return dataset\n",
    "\n",
    "dataset = loadDataset(path)\n",
    "for i in range(20):\n",
    "    print('')\n",
    "    x = random.choice(dataset)\n",
    "    print(x['query'])\n",
    "    print(x['wellFormedAnswers'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'i', 'can', \"n't\", 'open', 'the', 'door', 'because', 'the', '30-year', 'old', '/', 'blond-hair', 'guy', 'does', \"n't\", 'want', 'to', 'let', 'me', 'in', '.', 'he', \"'s\", 'mean', ',', 'is', \"n't\", 'he', '?', 'i', 'can', \"n't\", 'go', 'in', '!', 'there', \"'s\", 'no', 'other', 'way', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# def processFinalPeriod(sentence1):\n",
    "# \tif (sentence1[len(sentence1)-1] == \".\"):\n",
    "# \t\tsentence1 = sentence1[:len(sentence1)-2] + \" .\"\n",
    "\n",
    "def insertCharIfSeq(sentence1,c,seq):\n",
    "    i = 0\n",
    "    indexes = [m.start() for m in re.finditer(seq, sentence1)]\n",
    "    for index in indexes:\n",
    "        sentence1 = sentence1[:index+i] + c + sentence1[index+i:]\n",
    "        i += 1\n",
    "    return sentence1\n",
    "\n",
    "def processContractions(sentence1):\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'s\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'m\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'ll\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'ve\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'re\")\n",
    "    sentence1 = insertCharIfSeq(sentence1,\" \",\"'d\")\n",
    "    return sentence1\n",
    "\n",
    "\n",
    "def processNegatives(sentence1):\n",
    "    i = 0\n",
    "    indexes = [m.start() for m in re.finditer(\"can't\", sentence1)]\n",
    "    for index in indexes:\n",
    "        sentence1 = sentence1[:index+i+3] + sentence1[index+i+2:]\n",
    "        i += 1\n",
    "    return insertCharIfSeq(sentence1,\" \",\"n't\")\n",
    "\n",
    "## WHAT TO DO WITH HYPHENS ??\n",
    "\n",
    "def tokenizeSentence(sentence1):\n",
    "#     processFinalPeriod(sentence1)\n",
    "    sentence1 = processContractions(sentence1)\n",
    "    sentence1 = processNegatives(sentence1)\n",
    "    s = sentence1.lower()\n",
    "    s = re.sub('''([.,!\"?$;:/#`()])''', r' \\1 ', s)\n",
    "    s = re.sub('\\s{2,}', ' ', s)\n",
    "    s = s.split()\n",
    "#     s = processHyphenIfUnknownWords(s,glove)\n",
    "    s.append('</s>')\n",
    "    s = ['<s>'] + s\n",
    "    return s\n",
    "\n",
    "def testTokenizeSentence():\n",
    "    sentence1 = \"I can't open the door because the 30-year old/blond-hair guy doesn't want to let me in. He's mean, isn't he? I can't go in! There's no other way!\"\n",
    "    words = tokenizeSentence(sentence1)\n",
    "    print(words)\n",
    "    \n",
    "testTokenizeSentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n",
      "... 100%\r"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def tokenizeDataset(dataset):\n",
    "    tokenized_dataset = list()\n",
    "    len_dataset = len(dataset)\n",
    "    print_every = math.floor(len_dataset / 10)\n",
    "    print('Tokenizing dataset...')\n",
    "    for i, data in enumerate(dataset):\n",
    "        tokenized_data = dict()\n",
    "        tokenized_data['answers'] = list()\n",
    "        tokenized_data['wellFormedAnswers'] = list()\n",
    "        tokenized_data['passages'] = list()\n",
    "        for answer in data['answers']:\n",
    "            tokenized_data['answers'].append(tokenizeSentence(answer))\n",
    "        for wf_answer in data['wellFormedAnswers']:\n",
    "            tokenized_data['wellFormedAnswers'].append(tokenizeSentence(wf_answer))\n",
    "        for passage in data['passages']:\n",
    "            passage_dict = dict()\n",
    "            passage_dict['passage_text'] = tokenizeSentence(passage['passage_text'])\n",
    "            tokenized_data['passages'].append(passage_dict)\n",
    "        if i>0 and i%print_every == 0:\n",
    "            print('... %d%%'%(i/print_every*10),end=\"\\r\")\n",
    "\n",
    "tokenizeDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "HIDDEN_SIZE = 256\n",
    "VOC_SIZE = 50000 #for both source and target\n",
    "OUTPUT_SIZE = VOC_SIZE #10 # ?? \n",
    "BASELINE_VOC_SIZE = 150000\n",
    "MAX_LENGTH = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class EncoderDecoderLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,embedding_size=EMBEDDING_SIZE,hidden_size=HIDDEN_SIZE,voc_size=VOC_SIZE):\n",
    "        super(EncoderLSTM,self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.voc_size = voc_size\n",
    "        \n",
    "        # Encoder\n",
    "        self.embedding = nn.Embedding(voc_size, embedding_size)\n",
    "        self.encoder_biltsm = nn.LSTM(embedding_size, hidden_size, num_layers =1, bidirectional=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_bilstm = nn.LSTM(self.embedding_size,self.hidden_size, num_layers=1, bidirectional = True)\n",
    "        self.attn_W = nn.Linear(hidden_size *2, max_length) #?\n",
    "        self.attn_v = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.lin_V1 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.lin_V2 = nn.Lineal(hidden_size, output_size)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(1,1,self.hidden_size))\n",
    "    \n",
    "    def encoder_forward(self, input, hidden):\n",
    "        emb = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.encoder_bilstm(input, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def decoder_forward(self,input,hidden):\n",
    "        emb = self.embedding(token).view(1,1,-1)\n",
    "        output, hidden = self.decoder_bilstm(emb,hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    \n",
    "    def forward(self,pair):        \n",
    "        text = pair[0]\n",
    "        summary = pair[1]\n",
    "        \n",
    "        text_length = len(text)\n",
    "        encoder_hidden = self.initHidden()        \n",
    "        h = Variable(torch.zeros(self.text_length, self.hidden_size))        \n",
    "        for ei in range(text_length):\n",
    "            encoder_output, encoder_hidden = encoder_forward(text[ei],encoder_hidden)\n",
    "            h[ei] = encoder_output\n",
    "                    \n",
    "        summary_length = len(summary)\n",
    "        decoder_hidden = self.initHidden()        \n",
    "        s = Variable(torch.zeros(self.summary_length, self.hidden_size))        \n",
    "        decoder_input = Varible(torch.longTensor([[SOS_token]]))        \n",
    "        for di in range(summary_length):\n",
    "            decoder_output, decoder_hidden = decoder_forward(decoder_input, decoder_hidden)\n",
    "            s[di] = decoder_hidden\n",
    "            decoder_input = summary[di]\n",
    "            \n",
    "        #attention distribution\n",
    "        Wh_Ws_d = self.attn_W(torch.cat((h,s),1))\n",
    "        e = self.attn_v(Wh_Ws_d)\n",
    "        a = F.softmax(e, dim=1)\n",
    "        h_star = torch.bmm(a,h)\n",
    "        \n",
    "        #vocabulary distribution\n",
    "        v1 = self.lin_V1(torch.cat((s,h_star),dim=1))\n",
    "        v2 = self.lin_V2(v1)\n",
    "        Pvocab = F.softmax(v2,dim=1)\n",
    "        \n",
    "        # find target word\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
