{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to classify pairs of sentences as \"entailment\", \"neutral\" or \"contradiction\".\n",
    "\"entailment\": one sentence can be deduced from the other.\n",
    "\"contraadiction\": One sentence contradicts the other.\n",
    "\"neutral\": the sentences do not entail or contradict each others.\n",
    "    \n",
    "The idea is to compute a similarity score between the sentences to then classify them in one of the 3 categories.\n",
    "The sentence simiralirity score will be based on words similarity scores:\n",
    "for each word in the sentence, we will compute a similaritry score with every other word in the sentence.\n",
    "\n",
    "We will use simple NN, that we will feed with word vectors from a pretrained Glove dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Glove vectors\n",
    "\n",
    "We use Glove vectors as the input of our NN.\n",
    "Those functions help manipulate (read) this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading glove\n",
      "Loaded 400000 word vectors from Glove\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "glove_path = \"NLI/glove.6B/glove.6B.200d.txt\"\n",
    "\n",
    "\n",
    "def load_glove_embeddings(path, word2idx, embedding_dim=50):\n",
    "    with open(path) as f:\n",
    "        embeddings = np.zeros((len(word2idx), embedding_dim))\n",
    "        for line in f.readlines():\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            index = word2idx.get(word)\n",
    "            if index:\n",
    "                vector = np.array(values[1:], dtype='float32')\n",
    "                embeddings[index] = vector\n",
    "        return torch.from_numpy(embeddings).float()\n",
    "\n",
    "def load_glove(path,limit=1000000000):\n",
    "    with open(path) as f:\n",
    "        glove = {}\n",
    "        i = 0\n",
    "        for line in f.readlines():\n",
    "            if i < limit:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                my_array = [float(x) for x in values[1:]]\n",
    "                #normalize to l2 = 1\n",
    "                norm2 = np.linalg.norm(np.array(my_array),2)\n",
    "                my_array = my_array / norm2\n",
    "                vector = torch.FloatTensor([my_array])\n",
    "                # vector = Variable(vector)\n",
    "                glove[word] = vector\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "        return glove\n",
    "\n",
    "print(\"...loading glove\")\n",
    "glove = load_glove(path=glove_path)\n",
    "print(\"Loaded %d word vectors from Glove\"%len(glove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNLI dataset\n",
    "\n",
    "## Loading SNLI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "SNLI_path = \"NLI/snli_1.0/snli_1.0_train.jsonl\"\n",
    "\n",
    "def loadSNLI(path,limit=100000000000):\n",
    "    print(\"...loading SNLI dataset\")\n",
    "    SNLI_train = list()\n",
    "    i = 0\n",
    "    for line in open(path, 'r'):\n",
    "        if i <limit:\n",
    "            data = json.loads(line)\n",
    "            if data['gold_label'] != '-':\n",
    "                SNLI_train.append(data)\n",
    "                i += 1\n",
    "        else:\n",
    "            print(\"Loaded %d pairs of sentences from SNLI dataset\"%len(SNLI_train))\n",
    "            return SNLI_train\n",
    "    print(\"Loaded %d pairs of sentences from SNLI dataset\"%len(SNLI_train))\n",
    "    return SNLI_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading SNLI dataset\n",
      "Loaded 549367 pairs of sentences from SNLI dataset\n"
     ]
    }
   ],
   "source": [
    "SNLI_train = loadSNLI(SNLI_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing SNLI dataset\n",
    "\n",
    "Tokenize + get word vectors.\n",
    "\n",
    "### Tokenize dataset\n",
    "\n",
    "We need to tokenize the dataset: string sentence --> list of words sentence.\n",
    "The OOV class will help determine if a word is OOV and keep track of the number of OOV words in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OOV:\n",
    "\tdef __init__(self,glove):\n",
    "\t\tself.OOVlist = list()\n",
    "\t\tself.numberOfPairsWithOOV = 0\n",
    "\t\tself.wordVectors = glove\n",
    "\n",
    "\tdef getData(self):\n",
    "\t\t# print(self.OOVlist)\n",
    "\t\treturn len(self.OOVlist), self.numberOfPairsWithOOV\n",
    "\n",
    "\tdef countOOVinCorpus(self,sentence):\n",
    "\t\tb = False\n",
    "\t\tfor word in sentence:\n",
    "\t\t\tif self.isOOV(word) and word not in self.OOVlist:\n",
    "\t\t\t\tself.OOVlist.append(word)\n",
    "\t\t\t\tb = True\n",
    "\t\tself.numberOfPairsWithOOV += 1 if b else 0\n",
    "\n",
    "\tdef isOOV(self,word):\n",
    "\t\tvect = self.wordVectors.get(word)\n",
    "\t\ttry:\n",
    "\t\t\t_ = vect.shape\n",
    "\t\texcept AttributeError:\n",
    "\t\t\t# print(\"Could not find vector for \"+word)\n",
    "\t\t\treturn True\n",
    "\t\treturn False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define helper functions to tokenize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'i', 'can', 'n', \"'\", 't', 'open', 'the', 'door', 'because', 'the', '30-year', 'old', '/', 'blond', '-', 'hair', 'guy', 'does', 'n', \"'\", 't', 'want', 'to', 'let', 'me', 'in', '.', 'he', \"'\", 's', 'mean', ',', 'is', 'n', \"'\", 't', 'he', '?', 'i', 'can', 'n', \"'\", 't', 'go', 'in', '!', 'there', \"'\", 's', 'not', 'other', 'way', '!', '</s>']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def processFinalPeriod(sentence1):\n",
    "\tif (sentence1[len(sentence1)-1] == \".\"):\n",
    "\t\tsentence1 = sentence1[:len(sentence1)-2] + \" .\"\n",
    "\n",
    "def insertCharIfSeq(sentence1,c,seq):\n",
    "\ti = 0\n",
    "\tindexes = [m.start() for m in re.finditer(seq, sentence1)]\n",
    "\tfor index in indexes:\n",
    "\t\tsentence1 = sentence1[:index+i] + c + sentence1[index+i:]\n",
    "\t\ti += 1\n",
    "\treturn sentence1\n",
    "\n",
    "def processContractions(sentence1):\n",
    "\tsentence1 = insertCharIfSeq(sentence1,\" \",\"'s\")\n",
    "\tsentence1 = insertCharIfSeq(sentence1,\" \",\"'m\")\n",
    "\tsentence1 = insertCharIfSeq(sentence1,\" \",\"'ll\")\n",
    "\tsentence1 = insertCharIfSeq(sentence1,\" \",\"'ve\")\n",
    "\tsentence1 = insertCharIfSeq(sentence1,\" \",\"'re\")\n",
    "\tsentence1 = insertCharIfSeq(sentence1,\" \",\"'d\")\n",
    "\treturn sentence1\n",
    "\n",
    "\n",
    "def processNegatives(sentence1):\n",
    "\ti = 0\n",
    "\tindexes = [m.start() for m in re.finditer(\"can't\", sentence1)]\n",
    "\tfor index in indexes:\n",
    "\t\tsentence1 = sentence1[:index+i+3] + sentence1[index+i+2:]\n",
    "\t\ti += 1\n",
    "\treturn insertCharIfSeq(sentence1,\" \",\"n't\")\n",
    "\n",
    "def processHyphenIfUnknownWords(words,glove):\t\n",
    "\tindexes = []\n",
    "\tnew_words = []\n",
    "\ti = 0\n",
    "\tmyOOV = OOV(glove)\n",
    "\tfor w in words:\n",
    "\t\tif \"-\" in w and myOOV.isOOV(w):\n",
    "\t\t\tindexes.append(i)\n",
    "\t\t\tnew_words += w.split(\"-\")\n",
    "\t\t\ti += 3\n",
    "\t\telse:\n",
    "\t\t\ti += 1\n",
    "\ti = 0\n",
    "\tfor i in range(len(indexes)):\n",
    "\t\tindex = indexes[i]\n",
    "\t\tdel words[index]\n",
    "\t\t# print (words)\n",
    "\t\twords.insert(index,new_words[i*2])\n",
    "\t\twords.insert(index+1,\"-\")\n",
    "\t\twords.insert(index+2,new_words[i*2+1])\n",
    "\treturn words\n",
    "\n",
    "def tokeniszeSentence(sentence1,glove):\n",
    "\tprocessFinalPeriod(sentence1)\n",
    "\tsentence1 = processContractions(sentence1)\n",
    "\tsentence1 = processNegatives(sentence1)\n",
    "\ts = sentence1.lower()\n",
    "\ts = re.sub('''([.,!'\"?$;:/#`()])''', r' \\1 ', s)\n",
    "\ts = re.sub('\\s{2,}', ' ', s)\n",
    "\ts = s.split()\n",
    "\ts = processHyphenIfUnknownWords(s,glove)\n",
    "\ts.append('</s>')\n",
    "\ts = ['<s>'] + s\n",
    "\treturn s\n",
    "\n",
    "def testTokenizeSentence():\n",
    "\tsentence1 = \"I can't open the door because the 30-year old/blond-hair guy doesn't want to let me in. He's mean, isn't he? I can't go in! There's not other way!\"\n",
    "\t# sentence1= \"red-hair blond-hair noisette black-hair\"\n",
    "\twords = tokeniszeSentence(sentence1,glove)\n",
    "\tprint(words)\n",
    "    \n",
    "testTokenizeSentence()\n",
    "myOOV = OOV(glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and getting word vectors for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeDataset(dataset):\n",
    "    print(\"...tokenizing and getting word embeddings for SNLI dataset\")\n",
    "    sentencesOOVwords = 0\n",
    "    OOVwords = []\n",
    "    dataset_tokenized = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        # if i<15:\n",
    "        sentence1 = tokeniszeSentence(dataset[i][\"sentence1\"],glove)\n",
    "        sentence2 = tokeniszeSentence(dataset[i][\"sentence2\"],glove)\n",
    "        dataset_tokenized[i]=dict()\n",
    "        dataset_tokenized[i][\"sentence1\"] = sentence1\n",
    "        dataset_tokenized[i][\"sentence2\"] = sentence2\n",
    "        myOOV.countOOVinCorpus(sentence1+sentence2)\n",
    "    \n",
    "    nOOVWwords, nPairsOOVwords = myOOV.getData()\n",
    "    print(\"%d OOV words\"%nOOVWwords)\n",
    "    print(\"%d pairs of sentences have OOV words for a total of %d sentence pairs\" \n",
    "          %(nPairsOOVwords,len(dataset)))\n",
    "    \n",
    "    return dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def semiSort(SNLI):\n",
    "    SNLI_len10, SNLI_len20, SNLI_len30, SNLI_len40, SNLIlen50, SNLI_long = [], [], [], [], [], []\n",
    "    for i in range(len(SNLI)):\n",
    "        l1, l2 = len(SNLI[i]['sentence1']), len(SNLI[i]['sentence2'])\n",
    "        l = l1 if l1>l2 else l2\n",
    "        if l<10:\n",
    "            SNLI_len10.append(SNLI[i])\n",
    "        elif l<20:\n",
    "            SNLI_len20.append(SNLI[i])\n",
    "        elif l<50:\n",
    "            SNLI_len30.append(SNLI[i])\n",
    "        elif l<50:\n",
    "            SNLI_len40.append(SNLI[i])\n",
    "        elif l<50:\n",
    "            SNLI_len50.append(SNLI[i])\n",
    "        elif l<50:\n",
    "            SNLI_long.append(SNLI[i])\n",
    "    return SNLI_len10 + SNLI_len20 + SNLI_len30 + SNLI_len40 + SNLIlen50 + SNLI_long\n",
    "\n",
    "def loadAndPreprocessDataset(path):\n",
    "    SNLI = loadSNLI(path)\n",
    "    random.shuffle(SNLI)\n",
    "    SNLI = semiSort(SNLI)\n",
    "    tokenized_SNLI = tokenizeDataset(SNLI)\n",
    "    return SNLI, tokenized_SNLI    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading SNLI dataset\n",
      "Loaded 549367 pairs of sentences from SNLI dataset\n",
      "...tokenizing and getting word embeddings for SNLI dataset\n",
      "6159 OOV words\n",
      "6023 pairs of sentences have OOV words for a total of 157582 sentence pairs\n"
     ]
    }
   ],
   "source": [
    "SNLI_train, SNLI_train_tokenized = loadAndPreprocessDataset('NLI/snli_1.0/snli_1.0_train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a cyclist\n",
      "A biker\n",
      "entailment\n",
      "A dog in a field.\n",
      "A dog is outdoors.\n",
      "entailment\n",
      "Two wet dogs.\n",
      "two dogs in rain\n",
      "neutral\n",
      "A dog in a field.\n",
      "a cat in a hamock\n",
      "contradiction\n",
      "A baby is laughing.\n",
      "A baby is crying.\n",
      "contradiction\n"
     ]
    }
   ],
   "source": [
    "for i in  range(5):\n",
    "    print(SNLI_train[i]['sentence1'])\n",
    "    print(SNLI_train[i]['sentence2'])\n",
    "    print(SNLI_train[i]['gold_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedind sentences to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'children', 'smiling', 'and', 'waving', 'at', 'camera', '</s>']\n",
      "torch.Size([1, 8, 200])\n",
      "torch.Size([4, 29, 200]) torch.Size([4, 29, 200])\n",
      "[(16, 9), (16, 9), (16, 9), (29, 19)]\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "\n",
      "(2 ,.,.) = \n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "\n",
      "(3 ,.,.) = \n",
      " -0.0107 -0.0589\n",
      " -0.0331 -0.0197\n",
      "  0.3436  0.0026\n",
      "[torch.FloatTensor of size 4x3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentenceTo2DTensor(sentence, embeddings, size=None):\n",
    "    if (not size) :\n",
    "        size = len(sentence)\n",
    "    V1 = torch.zeros(size,200)\n",
    "    for i, w1 in enumerate(sentence):\n",
    "        v1 = embeddings.get(w1) if w1 not in myOOV.OOVlist else torch.FloatTensor([np.random.rand(1,200)])\n",
    "        V1[i] = v1\n",
    "    return V1\n",
    "\n",
    "def sentenceTo3DTensor(sentence,embeddings):\n",
    "    V1 = torch.zeros(1,len(sentence),200)\n",
    "    V1[0] = sentenceTo2DTensor(sentence,embeddings)\n",
    "    return Variable(V1)\n",
    "\n",
    "def batchesSentencesToTensors(start,size,dataset,embeddings):\n",
    "    maxlength = 0\n",
    "    for i in range(start,start+size):\n",
    "        l1, l2 = len(dataset[i]['sentence1']), len(dataset[i]['sentence2'])\n",
    "        l = l1 if l1>l2 else l2\n",
    "        maxlength = l if l>maxlength else maxlength\n",
    "    Va = torch.zeros(size,maxlength,200)\n",
    "    Vb = torch.zeros(size,maxlength,200)\n",
    "    lengths = []\n",
    "    for i in range(start,start+size):\n",
    "        sentence1, sentence2 = dataset[i]['sentence1'], dataset[i]['sentence2']\n",
    "#         print(sentence1,sentence2)\n",
    "        Va[i-start], Vb[i-start] = sentenceTo2DTensor(sentence1,embeddings,maxlength), sentenceTo2DTensor(sentence2,embeddings,maxlength)\n",
    "        lengths.append((len(sentence1),len(sentence2)))\n",
    "    Va, Vb = Variable(Va), Variable(Vb)\n",
    "    \n",
    "    return Va, Vb, lengths\n",
    "        \n",
    "    \n",
    "s1 = SNLI_train_tokenized[5][\"sentence1\"]\n",
    "print(s1)\n",
    "V1 = sentenceTo3DTensor(s1,glove) \n",
    "print(V1.size())\n",
    "Va, Vb, lengths = batchesSentencesToTensors(6,4,SNLI_train_tokenized,glove)\n",
    "sa = Va.size()\n",
    "print(sa,Vb.size())\n",
    "print(lengths)\n",
    "print(Va[:,sa[1]-3:,198:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man looks at the camera as he holds a small soldering iron near a magnifying glass and circuit board. A man looking at the internal components of a camera. entailment\n",
      "A group of friends are deciding what they should eat today. Some people are gathered at a table. entailment\n",
      "Four men play a frisbee game on a grass field. Four men play a game. entailment\n",
      "torch.Size([4, 16, 200]) torch.Size([4, 16, 200]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "all_categories = ['entailment', 'neutral', 'contradiction']\n",
    "\n",
    "import random\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.data.topk(1)\n",
    "    category_i = top_i[0]\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "# print(categoryFromOutput(output[0]))\n",
    "\n",
    "def getTrainingExample(dataset,dataset_tokenized,i):\n",
    "    category = dataset[i][\"gold_label\"]\n",
    "    category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
    "    s1, s2 = dataset[i][\"sentence1\"], dataset[i][\"sentence2\"]\n",
    "    x1, x2 = dataset_tokenized[i][\"sentence1\"], dataset_tokenized[i][\"sentence2\"]\n",
    "    a, b = sentenceTo3DTensor(x1,glove), sentenceTo3DTensor(x2,glove)\n",
    "    return category, s1, s2, category_tensor, a, b\n",
    "\n",
    "def randomTrainingExample(dataset,dataset_tokenized):\n",
    "    i = random.randint(0,len(dataset)-1)\n",
    "    category, s1, s2, category_tensor, a, b = getTrainingExample(dataset,dataset_tokenized,i)\n",
    "    return category, s1, s2, category_tensor, a, b\n",
    "\n",
    "def getTrainingBatch(start,size,dataset,dataset_tokenized,embeddings):\n",
    "    A, B, l = batchesSentencesToTensors(start,size,dataset_tokenized,embeddings)\n",
    "    array = np.zeros(size)\n",
    "    C = torch.LongTensor(array)\n",
    "    for i in range(start,start+size):\n",
    "        category = dataset[i][\"gold_label\"]\n",
    "        C[i-start] = all_categories.index(category)\n",
    "    return Variable(C), A, B\n",
    "\n",
    "for j in range(0,3):\n",
    "    category, s1, s2, category_tensor, a, b = randomTrainingExample(SNLI_train,SNLI_train_tokenized)\n",
    "    print(s1,s2,category)\n",
    "    \n",
    "C, A, B = getTrainingBatch(4,4,SNLI_train,SNLI_train_tokenized,glove)\n",
    "print(A.size(),B.size(),C.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing training, dev and test sets TODO\n",
    "\n",
    "+ cf paper (padding, semi sorting, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "## Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 200]) torch.Size([4, 8, 200])\n",
      "Variable containing:\n",
      "-1.1249 -1.3312 -0.8888\n",
      "-1.0459 -1.5082 -0.8502\n",
      "-1.1967 -1.4347 -0.7774\n",
      "-1.1217 -1.2129 -0.9757\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "D_IN = 200\n",
    "D_HIDDEN = 200\n",
    "D_OUT_MLP = 1\n",
    "D_OUT = 3\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self,dropout_ratio=0.2,d_in=D_IN,d_out=D_OUT,d_hidden=D_HIDDEN):\n",
    "#                  d_out_mlp = D_OUT_MLP):\n",
    "        super(NN, self).__init__()\n",
    "        n = 0.01\n",
    "        self.MLP1_h1 = nn.Linear(d_in,d_hidden)\n",
    "#         self.MLP1_h1.weight.data.normal_(-n,n)\n",
    "#         self.MLP1_h2 = nn.Linear(d_hidden,d_hidden)\n",
    "#         self.MLP1_h2.weight.data.normal_(-n,n)   \n",
    "        \n",
    "        self.MLP2_h1 = nn.Linear(d_in*2,d_hidden)\n",
    "#         self.MLP2_h1.weight.data.normal_(-n,n)\n",
    "#         self.MLP2_h2 = nn.Linear(d_hidden,d_hidden)\n",
    "#         self.MLP2_h2.weight.data.normal_(-n,n)\n",
    "        \n",
    "        self.MLP3_h1 = nn.Linear(d_in*2,d_hidden)\n",
    "#         self.MLP3_h1.weight.data.normal_(-n,n)\n",
    "#         self.MLP3_h2 = nn.Linear(d_hidden,d_hidden)\n",
    "#         self.MLP3_h2.weight.data.normal_(-n,n)\n",
    "        self.MLP3_out = nn.Linear(d_hidden,d_out)\n",
    "#         self.MLP3_out.weight.data.normal_(-n,n)\n",
    "        \n",
    "        self.MLP_drop = nn.Dropout(p=dropout_ratio)\n",
    "        \n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "        self.softmaxCol = nn.Softmax(0)\n",
    "        self.softmaxLine = nn.Softmax(1)\n",
    "        \n",
    "    def forward(self,a,b):\n",
    "        \n",
    "        # MLP1 (F)\n",
    "        \n",
    "        Fa = F.relu(self.MLP1_h1(a))\n",
    "        Fa = self.MLP_drop(Fa)\n",
    "#         Fa = F.relu(self.MLP1_h2(Fa))\n",
    "#         Fa = self.MLP1_out(Fa)        \n",
    "        Fb = F.relu(self.MLP1_h1(b))\n",
    "        Fb = self.MLP_drop(Fb)\n",
    "#         Fb = F.relu(self.MLP1_h2(Fb))\n",
    "#         Fb = self.MLP1_out(Fb)\n",
    "        \n",
    "        # Attend\n",
    "        \n",
    "        # Attention eight matrix\n",
    "        Fb = Fb.permute(0,2,1)\n",
    "        E = torch.bmm(Fa,Fb)\n",
    "        # Normalize attention wights\n",
    "        E_softmaxCol = self.softmaxCol(E)\n",
    "        E_softmaxLine = self.softmaxLine(E).permute(0,2,1)  \n",
    "        # Softly aligned subphrases\n",
    "        beta = torch.bmm(E_softmaxCol,b) # subphrase b aligned with a\n",
    "        alpha = torch.bmm(E_softmaxLine,a) # subphrase a aligned with b\n",
    "                \n",
    "        # MLP2 (G)\n",
    "        \n",
    "        aBeta = torch.cat([a,beta],2)\n",
    "        bAlpha = torch.cat([b,alpha],2)\n",
    "        v1 = F.relu(self.MLP2_h1(aBeta))  \n",
    "        v1 = self.MLP_drop(v1)\n",
    "#         v1 = F.relu(self.MLP2_h2(v1))\n",
    "        v2 = F.relu(self.MLP2_h1(bAlpha))\n",
    "        v2 = self.MLP_drop(v2)\n",
    "#         v2 = F.relu(self.MLP2_h2(v2))\n",
    "        \n",
    "        # Aggregate\n",
    "        v1 = torch.sum(v1,1)\n",
    "        v2 = torch.sum(v2,1)\n",
    "                \n",
    "        # MLP3 (H)\n",
    "        y = torch.cat([v1,v2],1)\n",
    "\n",
    "#         Fa = torch.sum(Fa,0)\n",
    "#         Fa = Fa.unsqueeze(0)\n",
    "#         Fb = torch.sum(Fb,0)\n",
    "#         Fb = Fb.unsqueeze(0)\n",
    "#         y = torch.cat([Fa,Fb],1)\n",
    "\n",
    "        y = self.MLP3_h1(y)\n",
    "        y = self.MLP_drop(y)\n",
    "        y = F.relu(y)\n",
    "#         y = F.relu(self.MLP3_h2(y))\n",
    "        y = self.MLP3_out(y)    \n",
    "        y = self.logSoftmax(y)\n",
    "        \n",
    "        \n",
    "        return y\n",
    "    \n",
    "network = NN()\n",
    "\n",
    "# s1, s2 = SNLI_train_tokenized[0][\"sentence1\"], SNLI_train_tokenized[0][\"sentence2\"]\n",
    "# a, b = sentenceToTensor(s1,glove), sentenceToTensor(s2,glove)\n",
    "# o = network(a,b)\n",
    "# print(o)\n",
    "\n",
    "Va, Vb, l = batchesSentencesToTensors(0,4,SNLI_train_tokenized,glove)\n",
    "print(Va.size(),Vb.size())\n",
    "output = network(Va,Vb)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "+ check Agrad optimization\n",
    "+ default initial accumulator vvalue 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.8197 -4.5017 -0.6009\n",
      "-1.7367 -3.9761 -0.2167\n",
      "-1.4263 -4.9519 -0.2841\n",
      "-0.4610 -3.9272 -1.0509\n",
      "[torch.FloatTensor of size 4x3]\n",
      " 0.4453611969947815\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.025\n",
    "\n",
    "def trainingStep(learning_rate, sentence1Tensor, sentence2Tensor, category_tensor):\n",
    "    network.zero_grad()\n",
    "    output = network(sentence1Tensor,sentence2Tensor)\n",
    "    loss = criterion(output, category_tensor)    \n",
    "    loss.backward()    \n",
    "    for p in network.parameters():\n",
    "#         print('new p')\n",
    "#         print(p.size())\n",
    "        p.data.add_(-learning_rate, p.grad.data)        \n",
    "    return output, loss.data[0], p.grad.data\n",
    "\n",
    "\n",
    "# output, loss, grad = train(a,b,category_tensor)\n",
    "output, loss, grad = trainingStep(learning_rate,A,B,C)\n",
    "print(output,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0h 1m 52s'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    h = math.floor(s/(60*60))\n",
    "    s = s - h*60*60\n",
    "    m = math.floor(s/60)\n",
    "    s -= m*60\n",
    "    return '%dh %dm %ds'%(h,m,s)\n",
    "\n",
    "timeSince(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10113 10% (0h 0m 30s) 8.024790 0.992082\n",
      "Construction men setting up train tracks.\n",
      "A house is being built.\n",
      "contradiction ✓\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.2664\n",
      "  1.1924\n",
      "  5.9877\n",
      "  5.8416\n",
      " -2.6126\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "20097 20% (0h 1m 1s) 7.857378 1.023414\n",
      "Boys play cricket on a field.\n",
      "Small boys play a game.\n",
      "entailment ✗ (neutral)\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.2679\n",
      "  1.1910\n",
      "  5.9854\n",
      "  5.8411\n",
      " -2.6138\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "30081 30% (0h 1m 31s) 7.632391 0.926153\n",
      "These two people are eating.\n",
      "There are people eating.\n",
      "entailment ✓\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.2685\n",
      "  1.1927\n",
      "  5.9852\n",
      "  5.8406\n",
      " -2.6148\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "40065 40% (0h 2m 2s) 7.719379 0.999412\n",
      "Uniformed children playing soccer\n",
      "Children play soccer.\n",
      "entailment ✓\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.2704\n",
      "  1.1951\n",
      "  5.9855\n",
      "  5.8413\n",
      " -2.6165\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "50049 50% (0h 2m 32s) 7.489885 0.963024\n",
      "Three passengers on a train car.\n",
      "They are in a train.\n",
      "entailment ✓\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.2722\n",
      "  1.1959\n",
      "  5.9834\n",
      "  5.8402\n",
      " -2.6186\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "60033 60% (0h 3m 3s) 7.394923 0.979237\n",
      "A father and son walking towards a fishing boat.\n",
      "The father and son walk to the fishing boat.\n",
      "neutral ✗ (entailment)\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.2744\n",
      "  1.1967\n",
      "  5.9832\n",
      "  5.8398\n",
      " -2.6237\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "70017 70% (0h 3m 34s) 6.599607 0.933845\n",
      "A man preparing his gondola for a short trip.\n",
      "A person is going to be using a boat.\n",
      "entailment ✓\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.2748\n",
      "  1.2003\n",
      "  5.9842\n",
      "  5.8389\n",
      " -2.6257\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "80001 80% (0h 4m 4s) 6.401988 0.892177\n",
      "A large tan dog sits on a grassy hill.\n",
      "Hills are always covered in grass.\n",
      "neutral ✗ (contradiction)\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.2769\n",
      "  1.2012\n",
      "  5.9840\n",
      "  5.8399\n",
      " -2.6310\n",
      "[torch.FloatTensor of size 5]\n",
      "\n",
      "90113 90% (0h 4m 35s) 7.326698 0.943610\n",
      "People sitting on a rug around ropes.\n",
      "People sit on the rug.\n",
      "contradiction ✗ (entailment)\n",
      "\n",
      "1.00000e-02 *\n",
      "  1.2806\n",
      "  1.2024\n",
      "  5.9849\n",
      "  5.8401\n",
      " -2.6335\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(network,n_iters,learning_rate,batch_size,dropout_ratio,print_every_bool=False):\n",
    "\n",
    "    print_every = n_iters/100*10\n",
    "    plot_every = print_every/10\n",
    "    \n",
    "    # keep track of losses for ploting\n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    \n",
    "    s = time.time()\n",
    "#     network = NN(dropout_ratio)\n",
    "    \n",
    "    it = 1\n",
    "    last_print, last_plot = 0, 0\n",
    "\n",
    "    while it<n_iters+1:\n",
    "    #     category, s1, s2, category_tensor, a, b = randomTrainingExample(SNLI_train,SNLI_train_tokenized)\n",
    "        if batch_size >1:\n",
    "            start = it%lenSNLI\n",
    "            start = 1 if (start + batch_size)>=lenSNLI else start\n",
    "            category_tensor, A, B = getTrainingBatch(start,batch_size,SNLI_train,SNLI_train_tokenized,glove)\n",
    "        else:\n",
    "            category, s1, s2, category_tensor, A, B = getTrainingExample(SNLI_train,SNLI_train_tokenized,it%lenSNLI)\n",
    "        output, loss, grad = trainingStep(learning_rate,A,B,category_tensor)\n",
    "        current_loss += loss\n",
    "\n",
    "        if print_every_bool and int(it/print_every)>last_print:\n",
    "            last_print += 1\n",
    "            category, s1, s2, category_tensor, a, b = randomTrainingExample(SNLI_train,SNLI_train_tokenized)\n",
    "#             print(a.size(),b.size())\n",
    "            output = network(a,b)\n",
    "            guess, guess_i = categoryFromOutput(output[0])\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            print ('%d %d%% (%s) %.6f %.6f'\n",
    "                   %(it, it/n_iters*100, timeSince(s), current_loss, loss))\n",
    "            print(s1)\n",
    "            print(s2)\n",
    "            print('%s %s'%(guess,correct))\n",
    "            print(network.MLP1_h1.weight.data[0][0:5])\n",
    "\n",
    "        if int(it/plot_every) > last_plot:\n",
    "            last_plot += 1\n",
    "            l = current_loss / plot_every\n",
    "            all_losses.append(l)\n",
    "            current_loss = 0\n",
    "            \n",
    "        it += batch_size\n",
    "            \n",
    "    return all_losses\n",
    "\n",
    "start = time.time()\n",
    "all_losses = train(network,100000,0.01,128,0.1,print_every_bool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x270820ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatingStep(sentence1Tensor, sentence2Tensor, category_tensor):\n",
    "    network.zero_grad()\n",
    "    output = network(sentence1Tensor,sentence2Tensor)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading SNLI dataset\n",
      "Loaded 9824 pairs of sentences from SNLI dataset\n",
      "...tokenizing and getting word embeddings for SNLI dataset\n",
      "6159 OOV words\n",
      "6023 pairs of sentences have OOV words for a total of 2433 sentence pairs\n"
     ]
    }
   ],
   "source": [
    "SNLI_test, SNLI_test_tokenized = loadAndPreprocessDataset('NLI/snli_1.0/snli_1.0_test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accrucary: 58.16%\n"
     ]
    }
   ],
   "source": [
    "n_categories = len(all_categories)\n",
    "\n",
    "#keep track of correct guesses in confusion matrix\n",
    "def evaluate(network,dataset,dataset_tokenized,batch_size=128,print_every_bool=False):\n",
    "    confusion = torch.zeros(n_categories, n_categories)\n",
    "    len_dataset = len(dataset)\n",
    "    print_every = len_dataset/10\n",
    "\n",
    "    it = 1\n",
    "    total_correct = 0\n",
    "    # Go through examples and record which are guessed correctly\n",
    "    while it<len_dataset:\n",
    "        if batch_size >1:\n",
    "            start = it%len_dataset\n",
    "            start = 1 if (start + batch_size)>=len_dataset else start\n",
    "            category_tensor, A, B = getTrainingBatch(start,batch_size,dataset,dataset_tokenized,glove)\n",
    "        else:\n",
    "            category, s1, s2, category_tensor, A, B = getTrainingExample(dataset,dataset_tokenized,it%len_dataset)\n",
    "        output = evaluatingStep(A,B,category_tensor)\n",
    "        for i in range(output.size()[0]):\n",
    "            guess, guess_i = categoryFromOutput(output[i])\n",
    "            category_i = int(category_tensor[i])\n",
    "            confusion[category_i][guess_i] += 1\n",
    "            total_correct += 1 if (category_i == guess_i) else 0\n",
    "        it += batch_size\n",
    "        \n",
    "    for i in range(n_categories):\n",
    "        confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "    acc = total_correct / len_dataset \n",
    "    \n",
    "    return acc\n",
    "\n",
    "acc = evaluate(network,SNLI_dev,SNLI_dev_tokenized,batch_size=1,print_every_bool=True)\n",
    "print('Overall accrucary: %.2f%%'%(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28af64da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Axes\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development - Getting best batch size, learning rate and dropout ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...loading SNLI dataset\n",
      "Loaded 9842 pairs of sentences from SNLI dataset\n",
      "...tokenizing and getting word embeddings for SNLI dataset\n",
      "6180 OOV words\n",
      "6044 pairs of sentences have OOV words for a total of 2366 sentence pairs\n"
     ]
    }
   ],
   "source": [
    "SNLI_dev, SNLI_dev_tokenized = loadAndPreprocessDataset('NLI/snli_1.0/snli_1.0_dev.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0h 10m 5s) Learning Rate: 0.100, dropout ratio: 0.10 --> Accuracy: 35.93%\n",
      "(0h 20m 9s) Learning Rate: 0.100, dropout ratio: 0.20 --> Accuracy: 33.85%\n",
      "(0h 30m 24s) Learning Rate: 0.100, dropout ratio: 0.30 --> Accuracy: 33.85%\n",
      "(0h 40m 43s) Learning Rate: 0.100, dropout ratio: 0.40 --> Accuracy: 33.85%\n",
      "(0h 51m 2s) Learning Rate: 0.100, dropout ratio: 0.50 --> Accuracy: 33.85%\n",
      "(1h 1m 21s) Learning Rate: 0.300, dropout ratio: 0.10 --> Accuracy: 33.85%\n",
      "(1h 11m 33s) Learning Rate: 0.300, dropout ratio: 0.20 --> Accuracy: 33.85%\n",
      "(1h 21m 46s) Learning Rate: 0.300, dropout ratio: 0.30 --> Accuracy: 35.93%\n",
      "(1h 32m 1s) Learning Rate: 0.300, dropout ratio: 0.40 --> Accuracy: 33.85%\n",
      "(1h 42m 8s) Learning Rate: 0.300, dropout ratio: 0.50 --> Accuracy: 33.85%\n",
      "(1h 52m 27s) Learning Rate: 0.600, dropout ratio: 0.10 --> Accuracy: 33.85%\n",
      "(2h 2m 47s) Learning Rate: 0.600, dropout ratio: 0.20 --> Accuracy: 33.85%\n",
      "(2h 12m 53s) Learning Rate: 0.600, dropout ratio: 0.30 --> Accuracy: 33.85%\n",
      "(2h 23m 0s) Learning Rate: 0.600, dropout ratio: 0.40 --> Accuracy: 33.85%\n",
      "(2h 33m 7s) Learning Rate: 0.600, dropout ratio: 0.50 --> Accuracy: 33.85%\n",
      "(2h 43m 12s) Learning Rate: 1.000, dropout ratio: 0.10 --> Accuracy: 33.85%\n",
      "(2h 53m 19s) Learning Rate: 1.000, dropout ratio: 0.20 --> Accuracy: 30.18%\n",
      "(3h 3m 27s) Learning Rate: 1.000, dropout ratio: 0.30 --> Accuracy: 33.85%\n",
      "(3h 13m 34s) Learning Rate: 1.000, dropout ratio: 0.40 --> Accuracy: 33.85%\n",
      "(3h 23m 42s) Learning Rate: 1.000, dropout ratio: 0.50 --> Accuracy: 33.85%\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.1,0.3,0.6,1] \n",
    "# batch_sizes = [1,2,4,8,16,32,64,128]\n",
    "dropout_ratios = [0.1,0.2,0.3,0.4,0.5]\n",
    "n_iters = 100000\n",
    "\n",
    "lenSNLI = len(SNLI_train)\n",
    "all_losses = {}\n",
    "accuracies = {}\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "for lr in learning_rates:\n",
    "    all_losses[lr] = {}\n",
    "    accuracies[lr] = {}\n",
    "    for dropout_r in dropout_ratios:\n",
    "        network = NN(dropout_r)\n",
    "        all_losses[lr][dropout_r] = train(network,n_iters,lr,1,dropout_r)  \n",
    "        accuracies[lr][dropout_r] = evaluate(network,SNLI_dev,SNLI_dev_tokenized,batch_size=1,print_every_bool=False)\n",
    "        print('(%s) Learning Rate: %.3f, dropout ratio: %.2f --> Accuracy: %.2f%%'\n",
    "                  %(timeSince(s),lr,dropout_r,accuracies[lr][dropout_r]*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(0h 10m 6s) Learning Rate: 0.001, dropout ratio: 0.10 --> Accuracy: 45.10%\n",
    "(0h 20m 18s) Learning Rate: 0.001, dropout ratio: 0.20 --> Accuracy: 44.51%\n",
    "(0h 30m 35s) Learning Rate: 0.001, dropout ratio: 0.30 --> Accuracy: 44.72%\n",
    "(0h 40m 43s) Learning Rate: 0.001, dropout ratio: 0.40 --> Accuracy: 42.39%\n",
    "(0h 50m 54s) Learning Rate: 0.001, dropout ratio: 0.50 --> Accuracy: 43.15%\n",
    "(1h 0m 57s) Learning Rate: 0.003, dropout ratio: 0.10 --> Accuracy: 49.32%\n",
    "(1h 10m 58s) Learning Rate: 0.003, dropout ratio: 0.20 --> Accuracy: 48.86%\n",
    "(1h 21m 1s) Learning Rate: 0.003, dropout ratio: 0.30 --> Accuracy: 52.41%\n",
    "(1h 31m 1s) Learning Rate: 0.003, dropout ratio: 0.40 --> Accuracy: 48.35%\n",
    "(1h 41m 2s) Learning Rate: 0.003, dropout ratio: 0.50 --> Accuracy: 46.79%\n",
    "(1h 51m 1s) Learning Rate: 0.006, dropout ratio: 0.10 --> Accuracy: 57.10%\n",
    "(2h 1m 3s) Learning Rate: 0.006, dropout ratio: 0.20 --> Accuracy: 54.86%\n",
    "(2h 11m 8s) Learning Rate: 0.006, dropout ratio: 0.30 --> Accuracy: 53.76%\n",
    "(2h 21m 10s) Learning Rate: 0.006, dropout ratio: 0.40 --> Accuracy: 53.97%\n",
    "(2h 31m 20s) Learning Rate: 0.006, dropout ratio: 0.50 --> Accuracy: 49.96%\n",
    "(2h 41m 36s) Learning Rate: 0.010, dropout ratio: 0.10 --> Accuracy: 53.68%\n",
    "(2h 51m 54s) Learning Rate: 0.010, dropout ratio: 0.20 --> Accuracy: 56.68%\n",
    "(3h 2m 5s) Learning Rate: 0.010, dropout ratio: 0.30 --> Accuracy: 56.59%\n",
    "(3h 12m 16s) Learning Rate: 0.010, dropout ratio: 0.40 --> Accuracy: 54.78%\n",
    "(3h 22m 27s) Learning Rate: 0.010, dropout ratio: 0.50 --> Accuracy: 51.90%\n",
    "(1h 50m 56s) Learning Rate: 0.030, dropout ratio: 0.10 --> Accuracy: 35.93%\n",
    "(3h 32m 39s) Learning Rate: 0.030, dropout ratio: 0.10 --> Accuracy: 35.93%\n",
    "(3h 42m 55s) Learning Rate: 0.030, dropout ratio: 0.20 --> Accuracy: 35.93%\n",
    "(3h 53m 15s) Learning Rate: 0.030, dropout ratio: 0.30 --> Accuracy: 35.93%\n",
    "(4h 3m 34s) Learning Rate: 0.030, dropout ratio: 0.40 --> Accuracy: 35.93%\n",
    "(4h 13m 53s) Learning Rate: 0.030, dropout ratio: 0.50 --> Accuracy: 33.85%\n",
    "(4h 24m 2s) Learning Rate: 0.060, dropout ratio: 0.10 --> Accuracy: 33.85%\n",
    "(4h 34m 9s) Learning Rate: 0.060, dropout ratio: 0.20 --> Accuracy: 33.85%\n",
    "(4h 44m 9s) Learning Rate: 0.060, dropout ratio: 0.30 --> Accuracy: 33.85%\n",
    "(4h 54m 9s) Learning Rate: 0.060, dropout ratio: 0.40 --> Accuracy: 33.85%\n",
    "(5h 4m 15s) Learning Rate: 0.060, dropout ratio: 0.50 --> Accuracy: 33.85%\n",
    "(0h 10m 5s) Learning Rate: 0.100, dropout ratio: 0.10 --> Accuracy: 35.93%\n",
    "(0h 20m 9s) Learning Rate: 0.100, dropout ratio: 0.20 --> Accuracy: 33.85%\n",
    "(0h 30m 24s) Learning Rate: 0.100, dropout ratio: 0.30 --> Accuracy: 33.85%\n",
    "(0h 40m 43s) Learning Rate: 0.100, dropout ratio: 0.40 --> Accuracy: 33.85%\n",
    "(0h 51m 2s) Learning Rate: 0.100, dropout ratio: 0.50 --> Accuracy: 33.85%\n",
    "(1h 1m 21s) Learning Rate: 0.300, dropout ratio: 0.10 --> Accuracy: 33.85%\n",
    "(1h 11m 33s) Learning Rate: 0.300, dropout ratio: 0.20 --> Accuracy: 33.85%\n",
    "(1h 21m 46s) Learning Rate: 0.300, dropout ratio: 0.30 --> Accuracy: 35.93%\n",
    "(1h 32m 1s) Learning Rate: 0.300, dropout ratio: 0.40 --> Accuracy: 33.85%\n",
    "(1h 42m 8s) Learning Rate: 0.300, dropout ratio: 0.50 --> Accuracy: 33.85%\n",
    "(1h 52m 27s) Learning Rate: 0.600, dropout ratio: 0.10 --> Accuracy: 33.85%\n",
    "(2h 2m 47s) Learning Rate: 0.600, dropout ratio: 0.20 --> Accuracy: 33.85%\n",
    "(2h 12m 53s) Learning Rate: 0.600, dropout ratio: 0.30 --> Accuracy: 33.85%\n",
    "(2h 23m 0s) Learning Rate: 0.600, dropout ratio: 0.40 --> Accuracy: 33.85%\n",
    "(2h 33m 7s) Learning Rate: 0.600, dropout ratio: 0.50 --> Accuracy: 33.85%\n",
    "(2h 43m 12s) Learning Rate: 1.000, dropout ratio: 0.10 --> Accuracy: 33.85%\n",
    "(2h 53m 19s) Learning Rate: 1.000, dropout ratio: 0.20 --> Accuracy: 30.18%\n",
    "(3h 3m 27s) Learning Rate: 1.000, dropout ratio: 0.30 --> Accuracy: 33.85%\n",
    "(3h 13m 34s) Learning Rate: 1.000, dropout ratio: 0.40 --> Accuracy: 33.85%\n",
    "(3h 23m 42s) Learning Rate: 1.000, dropout ratio: 0.50 --> Accuracy: 33.85%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Best models:\n",
    "(1h 51m 1s) Learning Rate: 0.006, dropout ratio: 0.10 --> Accuracy: \t\t57.10%\n",
    "    (2h 1m 3s) Learning Rate: 0.006, dropout ratio: 0.20 --> Accuracy: \t\t54.86%\n",
    "(2h 51m 54s) Learning Rate: 0.010, dropout ratio: 0.20 --> Accuracy: \t\t56.68%\n",
    "    (3h 2m 5s) Learning Rate: 0.010, dropout ratio: 0.30 --> Accuracy: \t\t56.59%\n",
    "(3h 12m 16s) Learning Rate: 0.010, dropout ratio: 0.40 --> Accuracy: \t\t54.78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain best models on more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0h 50m 45s) Learning Rate: 0.006, dropout ratio: 0.10 --> Accuracy: 72.40%\n",
      "(18h 26m 25s) Learning Rate: 0.006, dropout ratio: 0.20 --> Accuracy: 70.50%\n",
      "(19h 17m 33s) Learning Rate: 0.010, dropout ratio: 0.20 --> Accuracy: 71.85%\n",
      "(20h 8m 31s) Learning Rate: 0.010, dropout ratio: 0.30 --> Accuracy: 68.93%\n",
      "(20h 59m 15s) Learning Rate: 0.010, dropout ratio: 0.40 --> Accuracy: 68.26%\n"
     ]
    }
   ],
   "source": [
    "best_models = [(0.006,0.1),(0.006,0.2),(0.01,0.2),(0.01,0.3),(0.01,0.4)]\n",
    "n_iters = 100000*5\n",
    "\n",
    "lenSNLI = len(SNLI_train)\n",
    "all_losses = {}\n",
    "accuracies = {}\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "for lr, dropout_r in best_models:\n",
    "    network = NN(dropout_r)\n",
    "    all_losses[(lr,dropout_r)] = train(network,n_iters,lr,1,dropout_r)  \n",
    "    accuracies[(lr,dropout_r)] = evaluate(network,SNLI_dev,SNLI_dev_tokenized,batch_size=1,print_every_bool=False)\n",
    "    print('(%s) Learning Rate: %.3f, dropout ratio: %.2f --> Accuracy: %.2f%%'\n",
    "              %(timeSince(s),lr,dropout_r,accuracies[(lr,dropout_r)]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
