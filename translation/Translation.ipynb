{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Helper class to create the one-hot vectors for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0 #start of sentence\n",
    "EOS_token = 1 #end of sentence\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess files\n",
    "\n",
    "Transform unicode in ascii and convert to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, unicodedata\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file\n",
    "\n",
    "Split line into pairs (english / other language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse = False):\n",
    "    print(\"Reading lines...\")\n",
    "    lines = open ('data/%s-%s/%s.txt'%(lang1, lang2, lang1), encoding = 'utf-8').read().strip().split('\\n')\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    else:\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it easier\n",
    "\n",
    "Keep only sort sentences that translate to the form \"I am\", \"He is\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = ('i am ', 'i m ','you are ', 'you re ', 'he is ', ' he s ', 'she is ', 'she s ', 'we are ', 'we re ', 'they are ', 'they re ')\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 149861 sentence pairs\n",
      "Trimmed to 10535 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4279\n",
      "eng 2737\n",
      "['je ne suis pas un grand photographe .', 'i m not a great photographer .']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def prepareData(lang1, lang2, reverse = False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print('Read %d sentence pairs'%len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print('Trimmed to %d sentence pairs'%len(pairs))\n",
    "    print('Counting words...')\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print('Counted words:')\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('fra', 'eng', True)\n",
    "example = random.choice(pairs)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ['nous sommes fatigues .', 'we re helpless .']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq model\n",
    "\n",
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "USE_CUDA = False\n",
    "INPUT_SIZE = input_lang.n_words\n",
    "HIDDEN_SIZE = 256\n",
    "OUTPUT_SIZE = output_lang.n_words\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        \n",
    "encoder = EncoderRNN(INPUT_SIZE,HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p = 0.1, max_length = MAX_LENGTH):\n",
    "        super(AttnDecoderRNN,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attn = nn.Linear(hidden_size *2, max_length)\n",
    "        self.attn_combine = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "    def forward(self,input,hidden,encoder_outputs):\n",
    "#         embedded = self.embedding(input).view(1,1,-1)\n",
    "#         embedded = self.dropout(embedded) #1, 1, 256\n",
    "#         # prev_hidden: 1, 1, 256\n",
    "#         attn_weights = self.attn(torch.cat([embedded,prev_hidden],2)) #1, 1, 10\n",
    "#         attn_weights = F.softmax(attn_weights,dim=2) #1, 1, 10\n",
    "#         encoder_outputs = encoder_outputs.unsqueeze(0) #1, 10, 256\n",
    "#         attn_applied = torch.bmm(attn_weights,encoder_outputs) # 1, 1, 256\n",
    "#         output = self.attn_combine(torch.cat([embedded,attn_applied],2)) #1, 1, 256\n",
    "#         output = F.relu(output) #1, 1, 256\n",
    "#         output, hidden = self.gru(output,prev_hidden) #1, 1, 256 ; 1, 1, 256\n",
    "#         output = self.out(output)\n",
    "#         output = F.softmax(output,dim=1)\n",
    "#         return output[0], hidden, attn_weights #1, 1, 256 ; 1, 1, 256 ; 1, 1, 10\n",
    "\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1,1,self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0456 -0.3023  0.0939  ...  -0.1898  0.1138  0.3477\n",
      "-0.1817  0.3257  0.0793  ...  -0.5152 -0.2456  0.0447\n",
      "-0.2697 -0.0340  0.3473  ...  -0.4264 -0.1177 -0.0347\n",
      "          ...             â‹±             ...          \n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 10x256]\n",
      "\n",
      "Variable containing:\n",
      " 39.9401\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_var, target_var = example[0], example[1]\n",
    "encoder = EncoderRNN(INPUT_SIZE,HIDDEN_SIZE)\n",
    "encoder_hidden = encoder.initHidden()\n",
    "input_length = input_var.size()[0]\n",
    "encoder_outputs = Variable(torch.zeros(MAX_LENGTH, encoder.hidden_size))\n",
    "encoder_outputs = encoder_outputs.cuda() if USE_CUDA else encoder_outputs\n",
    "for ei in range(input_length):\n",
    "    encoder_output, encoder_hidden = encoder(input_var[ei], encoder_hidden)\n",
    "    encoder_outputs[ei] = encoder_output[0][0]     \n",
    "print(encoder_outputs)\n",
    "\n",
    "decoder = AttnDecoderRNN(HIDDEN_SIZE,OUTPUT_SIZE)\n",
    "decoder_hidden = decoder.initHidden()\n",
    "target_length = target_var.size()[0]\n",
    "loss = 0\n",
    "decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "decoder_input = decoder_input.cuda() if USE_CUDA else decoder_input\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Feed the target as the next input\n",
    "for di in range(target_length):\n",
    "    decoder_output, decoder_hidden, decoder_attn = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    loss += criterion(decoder_output, target_var[di])\n",
    "    decoder_input = target_var[di]\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "## Prepare data\n",
    "\n",
    "Get one hot vectors for each word in sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang,sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def variableFromSentence(lang,sentence):\n",
    "    indexes = indexesFromSentence(lang,sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1,1))\n",
    "    if USE_CUDA:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "    \n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang,pair[0])\n",
    "    target_variable = variableFromSentence(output_lang,pair[1])\n",
    "    return (input_variable, target_variable)\n",
    "\n",
    "input_var, target_var = variablesFromPair(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.960744380950928"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEACHER_FORCING_RATIO = 0.5\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(input_var, target_var, encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_var.size()[0]\n",
    "    target_length = target_var.size()[0]\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if USE_CUDA else encoder_outputs\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_var[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "        \n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if USE_CUDA else decoder_input\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_var[di])\n",
    "            decoder_input = target_var[di]\n",
    "            \n",
    "    else:\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_var[di])\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if USE_CUDA else decoder_input\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "                \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length\n",
    "\n",
    "encoder_opt = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder_opt = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "train(input_var,target_var,encoder,decoder,encoder_opt,decoder_opt,nn.NLLLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep track of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s/60)\n",
    "    s -= m*60\n",
    "    return '%dm %ds' % (m,s)\n",
    "\n",
    "def timeSince(since,percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s),asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "#     plt.figure()\n",
    "#     fig, ax = plt.subplots()\n",
    "#     # this locator puts ticks at regular intervals\n",
    "#     loc = ticker.MultipleLocator(base=0.2)\n",
    "#     ax.yaxis.set_major_locator(loc)\n",
    "#     plt.plot(points)    \n",
    "    plt.figure()\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0 # reset every print_every\n",
    "    plot_loss_total = 0 # reset every plot_every\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr = learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr = learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 22s (- 7m 5s) (250 5%) 3.8547\n",
      "0m 45s (- 6m 50s) (500 10%) 3.3445\n",
      "1m 9s (- 6m 33s) (750 15%) 3.1302\n",
      "1m 33s (- 6m 12s) (1000 20%) 3.0400\n",
      "1m 57s (- 5m 52s) (1250 25%) 3.0261\n",
      "2m 21s (- 5m 30s) (1500 30%) 2.9283\n",
      "2m 46s (- 5m 8s) (1750 35%) 2.9453\n",
      "3m 10s (- 4m 45s) (2000 40%) 2.7761\n",
      "3m 35s (- 4m 23s) (2250 45%) 2.8259\n",
      "3m 59s (- 3m 59s) (2500 50%) 2.6327\n",
      "4m 24s (- 3m 36s) (2750 55%) 2.5856\n",
      "4m 49s (- 3m 12s) (3000 60%) 2.6956\n",
      "5m 14s (- 2m 49s) (3250 65%) 2.6116\n",
      "5m 39s (- 2m 25s) (3500 70%) 2.7085\n",
      "6m 3s (- 2m 1s) (3750 75%) 2.5469\n",
      "6m 28s (- 1m 37s) (4000 80%) 2.6563\n",
      "6m 53s (- 1m 12s) (4250 85%) 2.5282\n",
      "7m 18s (- 0m 48s) (4500 90%) 2.4260\n",
      "7m 42s (- 0m 24s) (4750 95%) 2.5467\n",
      "8m 7s (- 0m 0s) (5000 100%) 2.5003\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113d905c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "all_losses = trainIters(encoder1, attn_decoder1, 5000, learning_rate=0.01, print_every=250, plot_every = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_losses)\n",
    "showPlot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "        \n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(len(pairs))\n",
    "        print(pair)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10535\n",
      "['elles se cachent dans les bois .', 'they re hiding in the woods .']\n",
      "> elles se cachent dans les bois .\n",
      "= they re hiding in the woods .\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-752866089bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluateRandomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-91-b63d3e5db9c9>\u001b[0m in \u001b[0;36mevaluateRandomly\u001b[0;34m(encoder, decoder, n)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
